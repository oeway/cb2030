{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwlylH9QdZIo"
   },
   "source": [
    "## VAE analysis of two lung cancer sets\n",
    "\n",
    "Here we training a VAE of two different datasets within the TCGA. We will first merge the two datasets and subsequently try to separate the samples based on their latent variables. This is made in analogue with the notebook on PCA.\n",
    "\n",
    "First we retrieve our two TCGA lungcancer data from cbioportal.org. One of the sets are from [Lung Adenocarcinomas](https://en.wikipedia.org/wiki/Adenocarcinoma_of_the_lung) and the other is from [Lung Squamous Cell Carcinomas](https://en.wikipedia.org/wiki/Squamous-cell_carcinoma_of_the_lung). The code for the retrieval of this data set is not important for the understanding of the analysis, but can be found in the module tcga_read. Execute the code and proceed to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "error",
     "timestamp": 1666273721193,
     "user": {
      "displayName": "Lukas Käll",
      "userId": "12032005584020165009"
     },
     "user_tz": -120
    },
    "id": "GA9iY-NndZIt",
    "outputId": "76b6afa9-5c2b-4ff8-f151-cb562396e212"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\") # Read loacal modules for tcga access and qvalue calculations\n",
    "import tcga_read as tcga\n",
    "\n",
    "luad = tcga.get_expression_data(\"../../data/luad.tsv.gz\", 'http://download.cbioportal.org/luad_tcga_pan_can_atlas_2018.tar.gz',\"data_RNA_Seq_v2_expression_median.txt\")\n",
    "lusc = tcga.get_expression_data(\"../../data/lusc.tsv.gz\", 'http://download.cbioportal.org/lusc_tcga_pan_can_atlas_2018.tar.gz',\"data_RNA_Seq_v2_expression_median.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4HT7jtTdZIv"
   },
   "source": [
    "We now merge the datasets, and see too that we only include transcripts that are measured in all the carcinomas with an count larger than 0. Further we scale the measurements so that every gene expression value is scaled between 0 and 1, using sk-learns [MinMaxScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nTGtXhUgdZIw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "combined = pd.concat([lusc, luad], axis=1, sort=False)\n",
    "combined.dropna(axis=0, how='any', inplace=True)\n",
    "combined = combined.loc[~(combined<=0.0).any(axis=1)]\n",
    "X=scaler.fit_transform(np.log2(combined).T).T\n",
    "combined = pd.DataFrame(data=X,index=combined.index,columns=combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgRZHdghdZIw"
   },
   "source": [
    "We are setting up an istance of a machine learning framework, [PyTorch](https://en.wikipedia.org/wiki/PyTorch). It will help us fitting the needed neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CIY4kACMdZIx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.utils.data\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "## We use a GPU and hence need cuda, https://en.wikipedia.org/wiki/CUDA\n",
    "no_cuda = False\n",
    "\n",
    "## Some arbitrarly selected training parameters\n",
    "batch_size, lr, epochs, log_interval = 128, 1e-3, 1000, 10\n",
    "\n",
    "## Some parameters governing the architecture.\n",
    "hidden_dim, latent_dim = 64, 2\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(4711)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a network on a GPU, we need a special data öoader that can transfer the data to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-kzuplUgj3Es"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7966, 0.7539, 0.5268,  ..., 0.4000, 0.1724, 0.3890],\n",
      "        [0.4545, 0.6363, 0.5624,  ..., 0.6170, 0.5138, 0.4735],\n",
      "        [0.0000, 0.7093, 0.6046,  ..., 0.0454, 0.4523, 0.3972],\n",
      "        ...,\n",
      "        [0.6600, 0.5818, 0.4055,  ..., 0.4112, 0.7615, 0.2131],\n",
      "        [0.6401, 0.1870, 0.6983,  ..., 0.6335, 0.7845, 0.2495],\n",
      "        [0.5654, 0.6486, 0.8129,  ..., 0.6818, 0.7986, 0.2701]])\n"
     ]
    }
   ],
   "source": [
    "class ExpressionDataset(Dataset):\n",
    "    def __init__(self, datapoints, labels):\n",
    "        self.x_dim = datapoints.shape[0]\n",
    "        self.datapoints = torch.tensor(datapoints.to_numpy().T, dtype=torch.float32)\n",
    "        print(self.datapoints)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.datapoints[idx],self.labels[idx]\n",
    "\n",
    "train_dataset = ExpressionDataset(combined,([1.0 for _ in lusc.columns]+[ 0.0 for _ in luad.columns]))\n",
    "#train_dataset = ExpressionDataset(combined,([\"LUSC\" for _ in lusc.columns]+[\"LUAD\" for _ in luad.columns]))\n",
    "#test_dataset  = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "x_dim  = train_dataset.x_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we design the VAE. We use an architecure where 13046 features are first throtteled down to 64 features (fc1) then to 2 features, which we predict both mean and variance for (fc21 and fc22).   \n",
    "\n",
    "We reparametrize those 2 variables, and then expand them to 64 (fc3) and 13046 (fc4) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(x_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, x_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        out = torch.sigmoid(self.fc4(h3))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, x_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we next select a gradient descent optimizer, [Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam), and select a fuction to optimize, the loss_function, and we define a train and test procedure to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, x_dim), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    #print(f\"BCE={BCE}, KLD={KLD}\")\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if epoch % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    if epoch % log_interval == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "#        for i, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "    if epoch % log_interval == 0:\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are set to run the procedure for 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0/994 (0%)]\tLoss: 8792.989258\n",
      "Train Epoch: 10 [128/994 (12%)]\tLoss: 8802.832031\n",
      "Train Epoch: 10 [256/994 (25%)]\tLoss: 8801.497070\n",
      "Train Epoch: 10 [384/994 (38%)]\tLoss: 8806.785156\n",
      "Train Epoch: 10 [512/994 (50%)]\tLoss: 8798.025391\n",
      "Train Epoch: 10 [640/994 (62%)]\tLoss: 8803.156250\n",
      "Train Epoch: 10 [768/994 (75%)]\tLoss: 8792.065430\n",
      "Train Epoch: 10 [686/994 (88%)]\tLoss: 8811.276148\n",
      "====> Epoch: 10 Average loss: 8800.7706\n",
      "====> Test set loss: 8797.6908\n",
      "Train Epoch: 20 [0/994 (0%)]\tLoss: 8738.829102\n",
      "Train Epoch: 20 [128/994 (12%)]\tLoss: 8732.951172\n",
      "Train Epoch: 20 [256/994 (25%)]\tLoss: 8746.095703\n",
      "Train Epoch: 20 [384/994 (38%)]\tLoss: 8754.061523\n",
      "Train Epoch: 20 [512/994 (50%)]\tLoss: 8742.980469\n",
      "Train Epoch: 20 [640/994 (62%)]\tLoss: 8748.702148\n",
      "Train Epoch: 20 [768/994 (75%)]\tLoss: 8730.905273\n",
      "Train Epoch: 20 [686/994 (88%)]\tLoss: 8758.124362\n",
      "====> Epoch: 20 Average loss: 8743.6574\n",
      "====> Test set loss: 8740.4844\n",
      "Train Epoch: 30 [0/994 (0%)]\tLoss: 8709.035156\n",
      "Train Epoch: 30 [128/994 (12%)]\tLoss: 8719.181641\n",
      "Train Epoch: 30 [256/994 (25%)]\tLoss: 8719.106445\n",
      "Train Epoch: 30 [384/994 (38%)]\tLoss: 8706.854492\n",
      "Train Epoch: 30 [512/994 (50%)]\tLoss: 8707.196289\n",
      "Train Epoch: 30 [640/994 (62%)]\tLoss: 8711.771484\n",
      "Train Epoch: 30 [768/994 (75%)]\tLoss: 8713.416016\n",
      "Train Epoch: 30 [686/994 (88%)]\tLoss: 8725.492347\n",
      "====> Epoch: 30 Average loss: 8713.6601\n",
      "====> Test set loss: 8712.1587\n",
      "Train Epoch: 40 [0/994 (0%)]\tLoss: 8691.051758\n",
      "Train Epoch: 40 [128/994 (12%)]\tLoss: 8705.744141\n",
      "Train Epoch: 40 [256/994 (25%)]\tLoss: 8706.104492\n",
      "Train Epoch: 40 [384/994 (38%)]\tLoss: 8710.945312\n",
      "Train Epoch: 40 [512/994 (50%)]\tLoss: 8700.839844\n",
      "Train Epoch: 40 [640/994 (62%)]\tLoss: 8702.417969\n",
      "Train Epoch: 40 [768/994 (75%)]\tLoss: 8703.071289\n",
      "Train Epoch: 40 [686/994 (88%)]\tLoss: 8719.269133\n",
      "====> Epoch: 40 Average loss: 8704.4977\n",
      "====> Test set loss: 8702.6975\n",
      "Train Epoch: 50 [0/994 (0%)]\tLoss: 8691.423828\n",
      "Train Epoch: 50 [128/994 (12%)]\tLoss: 8701.709961\n",
      "Train Epoch: 50 [256/994 (25%)]\tLoss: 8681.285156\n",
      "Train Epoch: 50 [384/994 (38%)]\tLoss: 8701.382812\n",
      "Train Epoch: 50 [512/994 (50%)]\tLoss: 8704.169922\n",
      "Train Epoch: 50 [640/994 (62%)]\tLoss: 8703.007812\n",
      "Train Epoch: 50 [768/994 (75%)]\tLoss: 8704.130859\n",
      "Train Epoch: 50 [686/994 (88%)]\tLoss: 8701.087372\n",
      "====> Epoch: 50 Average loss: 8698.4474\n",
      "====> Test set loss: 8697.1781\n",
      "Train Epoch: 60 [0/994 (0%)]\tLoss: 8705.998047\n",
      "Train Epoch: 60 [128/994 (12%)]\tLoss: 8697.439453\n",
      "Train Epoch: 60 [256/994 (25%)]\tLoss: 8687.780273\n",
      "Train Epoch: 60 [384/994 (38%)]\tLoss: 8690.163086\n",
      "Train Epoch: 60 [512/994 (50%)]\tLoss: 8680.722656\n",
      "Train Epoch: 60 [640/994 (62%)]\tLoss: 8702.136719\n",
      "Train Epoch: 60 [768/994 (75%)]\tLoss: 8711.101562\n",
      "Train Epoch: 60 [686/994 (88%)]\tLoss: 8698.582908\n",
      "====> Epoch: 60 Average loss: 8696.6850\n",
      "====> Test set loss: 8696.7358\n",
      "Train Epoch: 70 [0/994 (0%)]\tLoss: 8696.956055\n",
      "Train Epoch: 70 [128/994 (12%)]\tLoss: 8705.936523\n",
      "Train Epoch: 70 [256/994 (25%)]\tLoss: 8689.166016\n",
      "Train Epoch: 70 [384/994 (38%)]\tLoss: 8672.213867\n",
      "Train Epoch: 70 [512/994 (50%)]\tLoss: 8695.043945\n",
      "Train Epoch: 70 [640/994 (62%)]\tLoss: 8700.744141\n",
      "Train Epoch: 70 [768/994 (75%)]\tLoss: 8684.583008\n",
      "Train Epoch: 70 [686/994 (88%)]\tLoss: 8698.263393\n",
      "====> Epoch: 70 Average loss: 8692.7004\n",
      "====> Test set loss: 8692.4507\n",
      "Train Epoch: 80 [0/994 (0%)]\tLoss: 8679.979492\n",
      "Train Epoch: 80 [128/994 (12%)]\tLoss: 8682.019531\n",
      "Train Epoch: 80 [256/994 (25%)]\tLoss: 8691.500977\n",
      "Train Epoch: 80 [384/994 (38%)]\tLoss: 8697.409180\n",
      "Train Epoch: 80 [512/994 (50%)]\tLoss: 8691.012695\n",
      "Train Epoch: 80 [640/994 (62%)]\tLoss: 8695.683594\n",
      "Train Epoch: 80 [768/994 (75%)]\tLoss: 8692.507812\n",
      "Train Epoch: 80 [686/994 (88%)]\tLoss: 8701.043367\n",
      "====> Epoch: 80 Average loss: 8691.1034\n",
      "====> Test set loss: 8689.8491\n",
      "Train Epoch: 90 [0/994 (0%)]\tLoss: 8675.479492\n",
      "Train Epoch: 90 [128/994 (12%)]\tLoss: 8681.206055\n",
      "Train Epoch: 90 [256/994 (25%)]\tLoss: 8696.506836\n",
      "Train Epoch: 90 [384/994 (38%)]\tLoss: 8689.298828\n",
      "Train Epoch: 90 [512/994 (50%)]\tLoss: 8703.167969\n",
      "Train Epoch: 90 [640/994 (62%)]\tLoss: 8698.019531\n",
      "Train Epoch: 90 [768/994 (75%)]\tLoss: 8682.553711\n",
      "Train Epoch: 90 [686/994 (88%)]\tLoss: 8686.757015\n",
      "====> Epoch: 90 Average loss: 8689.1951\n",
      "====> Test set loss: 8688.8583\n",
      "Train Epoch: 100 [0/994 (0%)]\tLoss: 8687.038086\n",
      "Train Epoch: 100 [128/994 (12%)]\tLoss: 8687.485352\n",
      "Train Epoch: 100 [256/994 (25%)]\tLoss: 8691.784180\n",
      "Train Epoch: 100 [384/994 (38%)]\tLoss: 8685.958008\n",
      "Train Epoch: 100 [512/994 (50%)]\tLoss: 8676.631836\n",
      "Train Epoch: 100 [640/994 (62%)]\tLoss: 8703.061523\n",
      "Train Epoch: 100 [768/994 (75%)]\tLoss: 8703.076172\n",
      "Train Epoch: 100 [686/994 (88%)]\tLoss: 8684.310587\n",
      "====> Epoch: 100 Average loss: 8690.0875\n",
      "====> Test set loss: 8686.5654\n",
      "Train Epoch: 110 [0/994 (0%)]\tLoss: 8686.594727\n",
      "Train Epoch: 110 [128/994 (12%)]\tLoss: 8672.970703\n",
      "Train Epoch: 110 [256/994 (25%)]\tLoss: 8700.313477\n",
      "Train Epoch: 110 [384/994 (38%)]\tLoss: 8691.208984\n",
      "Train Epoch: 110 [512/994 (50%)]\tLoss: 8678.824219\n",
      "Train Epoch: 110 [640/994 (62%)]\tLoss: 8696.794922\n",
      "Train Epoch: 110 [768/994 (75%)]\tLoss: 8693.449219\n",
      "Train Epoch: 110 [686/994 (88%)]\tLoss: 8690.885204\n",
      "====> Epoch: 110 Average loss: 8688.8197\n",
      "====> Test set loss: 8684.9413\n",
      "Train Epoch: 120 [0/994 (0%)]\tLoss: 8681.099609\n",
      "Train Epoch: 120 [128/994 (12%)]\tLoss: 8685.179688\n",
      "Train Epoch: 120 [256/994 (25%)]\tLoss: 8683.704102\n",
      "Train Epoch: 120 [384/994 (38%)]\tLoss: 8677.593750\n",
      "Train Epoch: 120 [512/994 (50%)]\tLoss: 8698.149414\n",
      "Train Epoch: 120 [640/994 (62%)]\tLoss: 8679.502930\n",
      "Train Epoch: 120 [768/994 (75%)]\tLoss: 8688.557617\n",
      "Train Epoch: 120 [686/994 (88%)]\tLoss: 8669.331633\n",
      "====> Epoch: 120 Average loss: 8683.2990\n",
      "====> Test set loss: 8682.9298\n",
      "Train Epoch: 130 [0/994 (0%)]\tLoss: 8683.843750\n",
      "Train Epoch: 130 [128/994 (12%)]\tLoss: 8680.257812\n",
      "Train Epoch: 130 [256/994 (25%)]\tLoss: 8673.781250\n",
      "Train Epoch: 130 [384/994 (38%)]\tLoss: 8694.502930\n",
      "Train Epoch: 130 [512/994 (50%)]\tLoss: 8679.898438\n",
      "Train Epoch: 130 [640/994 (62%)]\tLoss: 8686.265625\n",
      "Train Epoch: 130 [768/994 (75%)]\tLoss: 8671.247070\n",
      "Train Epoch: 130 [686/994 (88%)]\tLoss: 8692.876276\n",
      "====> Epoch: 130 Average loss: 8682.5311\n",
      "====> Test set loss: 8682.5863\n",
      "Train Epoch: 140 [0/994 (0%)]\tLoss: 8671.408203\n",
      "Train Epoch: 140 [128/994 (12%)]\tLoss: 8677.071289\n",
      "Train Epoch: 140 [256/994 (25%)]\tLoss: 8672.579102\n",
      "Train Epoch: 140 [384/994 (38%)]\tLoss: 8694.656250\n",
      "Train Epoch: 140 [512/994 (50%)]\tLoss: 8679.637695\n",
      "Train Epoch: 140 [640/994 (62%)]\tLoss: 8679.588867\n",
      "Train Epoch: 140 [768/994 (75%)]\tLoss: 8691.775391\n",
      "Train Epoch: 140 [686/994 (88%)]\tLoss: 8688.276148\n",
      "====> Epoch: 140 Average loss: 8681.6809\n",
      "====> Test set loss: 8682.4696\n",
      "Train Epoch: 150 [0/994 (0%)]\tLoss: 8701.578125\n",
      "Train Epoch: 150 [128/994 (12%)]\tLoss: 8671.614258\n",
      "Train Epoch: 150 [256/994 (25%)]\tLoss: 8677.709961\n",
      "Train Epoch: 150 [384/994 (38%)]\tLoss: 8685.769531\n",
      "Train Epoch: 150 [512/994 (50%)]\tLoss: 8688.815430\n",
      "Train Epoch: 150 [640/994 (62%)]\tLoss: 8684.766602\n",
      "Train Epoch: 150 [768/994 (75%)]\tLoss: 8681.404297\n",
      "Train Epoch: 150 [686/994 (88%)]\tLoss: 8684.390944\n",
      "====> Epoch: 150 Average loss: 8684.5096\n",
      "====> Test set loss: 8681.6066\n",
      "Train Epoch: 160 [0/994 (0%)]\tLoss: 8659.448242\n",
      "Train Epoch: 160 [128/994 (12%)]\tLoss: 8667.847656\n",
      "Train Epoch: 160 [256/994 (25%)]\tLoss: 8689.197266\n",
      "Train Epoch: 160 [384/994 (38%)]\tLoss: 8702.049805\n",
      "Train Epoch: 160 [512/994 (50%)]\tLoss: 8688.599609\n",
      "Train Epoch: 160 [640/994 (62%)]\tLoss: 8686.058594\n",
      "Train Epoch: 160 [768/994 (75%)]\tLoss: 8687.316406\n",
      "Train Epoch: 160 [686/994 (88%)]\tLoss: 8649.063776\n",
      "====> Epoch: 160 Average loss: 8679.5921\n",
      "====> Test set loss: 8678.2451\n",
      "Train Epoch: 170 [0/994 (0%)]\tLoss: 8696.026367\n",
      "Train Epoch: 170 [128/994 (12%)]\tLoss: 8664.372070\n",
      "Train Epoch: 170 [256/994 (25%)]\tLoss: 8687.972656\n",
      "Train Epoch: 170 [384/994 (38%)]\tLoss: 8673.672852\n",
      "Train Epoch: 170 [512/994 (50%)]\tLoss: 8694.660156\n",
      "Train Epoch: 170 [640/994 (62%)]\tLoss: 8675.306641\n",
      "Train Epoch: 170 [768/994 (75%)]\tLoss: 8675.960938\n",
      "Train Epoch: 170 [686/994 (88%)]\tLoss: 8650.069515\n",
      "====> Epoch: 170 Average loss: 8678.0756\n",
      "====> Test set loss: 8677.2308\n",
      "Train Epoch: 180 [0/994 (0%)]\tLoss: 8688.310547\n",
      "Train Epoch: 180 [128/994 (12%)]\tLoss: 8685.365234\n",
      "Train Epoch: 180 [256/994 (25%)]\tLoss: 8688.819336\n",
      "Train Epoch: 180 [384/994 (38%)]\tLoss: 8667.927734\n",
      "Train Epoch: 180 [512/994 (50%)]\tLoss: 8674.769531\n",
      "Train Epoch: 180 [640/994 (62%)]\tLoss: 8677.950195\n",
      "Train Epoch: 180 [768/994 (75%)]\tLoss: 8683.894531\n",
      "Train Epoch: 180 [686/994 (88%)]\tLoss: 8646.322066\n",
      "====> Epoch: 180 Average loss: 8677.5858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 8676.6530\n",
      "Train Epoch: 190 [0/994 (0%)]\tLoss: 8675.082031\n",
      "Train Epoch: 190 [128/994 (12%)]\tLoss: 8680.291992\n",
      "Train Epoch: 190 [256/994 (25%)]\tLoss: 8691.002930\n",
      "Train Epoch: 190 [384/994 (38%)]\tLoss: 8667.251953\n",
      "Train Epoch: 190 [512/994 (50%)]\tLoss: 8683.860352\n",
      "Train Epoch: 190 [640/994 (62%)]\tLoss: 8684.139648\n",
      "Train Epoch: 190 [768/994 (75%)]\tLoss: 8681.730469\n",
      "Train Epoch: 190 [686/994 (88%)]\tLoss: 8643.454082\n",
      "====> Epoch: 190 Average loss: 8676.8295\n",
      "====> Test set loss: 8676.1793\n",
      "Train Epoch: 200 [0/994 (0%)]\tLoss: 8681.663086\n",
      "Train Epoch: 200 [128/994 (12%)]\tLoss: 8668.091797\n",
      "Train Epoch: 200 [256/994 (25%)]\tLoss: 8673.872070\n",
      "Train Epoch: 200 [384/994 (38%)]\tLoss: 8677.295898\n",
      "Train Epoch: 200 [512/994 (50%)]\tLoss: 8683.222656\n",
      "Train Epoch: 200 [640/994 (62%)]\tLoss: 8665.553711\n",
      "Train Epoch: 200 [768/994 (75%)]\tLoss: 8672.204102\n",
      "Train Epoch: 200 [686/994 (88%)]\tLoss: 8689.522959\n",
      "====> Epoch: 200 Average loss: 8676.0331\n",
      "====> Test set loss: 8675.7525\n",
      "Train Epoch: 210 [0/994 (0%)]\tLoss: 8671.763672\n",
      "Train Epoch: 210 [128/994 (12%)]\tLoss: 8677.096680\n",
      "Train Epoch: 210 [256/994 (25%)]\tLoss: 8682.997070\n",
      "Train Epoch: 210 [384/994 (38%)]\tLoss: 8668.712891\n",
      "Train Epoch: 210 [512/994 (50%)]\tLoss: 8686.960938\n",
      "Train Epoch: 210 [640/994 (62%)]\tLoss: 8677.969727\n",
      "Train Epoch: 210 [768/994 (75%)]\tLoss: 8674.552734\n",
      "Train Epoch: 210 [686/994 (88%)]\tLoss: 8667.114796\n",
      "====> Epoch: 210 Average loss: 8676.1611\n",
      "====> Test set loss: 8674.9220\n",
      "Train Epoch: 220 [0/994 (0%)]\tLoss: 8679.488281\n",
      "Train Epoch: 220 [128/994 (12%)]\tLoss: 8672.788086\n",
      "Train Epoch: 220 [256/994 (25%)]\tLoss: 8678.673828\n",
      "Train Epoch: 220 [384/994 (38%)]\tLoss: 8664.958008\n",
      "Train Epoch: 220 [512/994 (50%)]\tLoss: 8674.798828\n",
      "Train Epoch: 220 [640/994 (62%)]\tLoss: 8682.339844\n",
      "Train Epoch: 220 [768/994 (75%)]\tLoss: 8671.398438\n",
      "Train Epoch: 220 [686/994 (88%)]\tLoss: 8675.672832\n",
      "====> Epoch: 220 Average loss: 8674.9949\n",
      "====> Test set loss: 8673.7796\n",
      "Train Epoch: 230 [0/994 (0%)]\tLoss: 8668.179688\n",
      "Train Epoch: 230 [128/994 (12%)]\tLoss: 8682.536133\n",
      "Train Epoch: 230 [256/994 (25%)]\tLoss: 8675.080078\n",
      "Train Epoch: 230 [384/994 (38%)]\tLoss: 8671.627930\n",
      "Train Epoch: 230 [512/994 (50%)]\tLoss: 8680.581055\n",
      "Train Epoch: 230 [640/994 (62%)]\tLoss: 8675.187500\n",
      "Train Epoch: 230 [768/994 (75%)]\tLoss: 8677.823242\n",
      "Train Epoch: 230 [686/994 (88%)]\tLoss: 8658.274872\n",
      "====> Epoch: 230 Average loss: 8674.1257\n",
      "====> Test set loss: 8673.2857\n",
      "Train Epoch: 240 [0/994 (0%)]\tLoss: 8679.279297\n",
      "Train Epoch: 240 [128/994 (12%)]\tLoss: 8672.828125\n",
      "Train Epoch: 240 [256/994 (25%)]\tLoss: 8669.332031\n",
      "Train Epoch: 240 [384/994 (38%)]\tLoss: 8668.832031\n",
      "Train Epoch: 240 [512/994 (50%)]\tLoss: 8668.259766\n",
      "Train Epoch: 240 [640/994 (62%)]\tLoss: 8672.191406\n",
      "Train Epoch: 240 [768/994 (75%)]\tLoss: 8686.494141\n",
      "Train Epoch: 240 [686/994 (88%)]\tLoss: 8680.869260\n",
      "====> Epoch: 240 Average loss: 8674.5764\n",
      "====> Test set loss: 8675.6113\n",
      "Train Epoch: 250 [0/994 (0%)]\tLoss: 8674.527344\n",
      "Train Epoch: 250 [128/994 (12%)]\tLoss: 8654.554688\n",
      "Train Epoch: 250 [256/994 (25%)]\tLoss: 8688.725586\n",
      "Train Epoch: 250 [384/994 (38%)]\tLoss: 8667.625000\n",
      "Train Epoch: 250 [512/994 (50%)]\tLoss: 8679.563477\n",
      "Train Epoch: 250 [640/994 (62%)]\tLoss: 8655.842773\n",
      "Train Epoch: 250 [768/994 (75%)]\tLoss: 8679.269531\n",
      "Train Epoch: 250 [686/994 (88%)]\tLoss: 8689.313776\n",
      "====> Epoch: 250 Average loss: 8673.2059\n",
      "====> Test set loss: 8671.8357\n",
      "Train Epoch: 260 [0/994 (0%)]\tLoss: 8674.718750\n",
      "Train Epoch: 260 [128/994 (12%)]\tLoss: 8668.565430\n",
      "Train Epoch: 260 [256/994 (25%)]\tLoss: 8682.090820\n",
      "Train Epoch: 260 [384/994 (38%)]\tLoss: 8661.922852\n",
      "Train Epoch: 260 [512/994 (50%)]\tLoss: 8687.230469\n",
      "Train Epoch: 260 [640/994 (62%)]\tLoss: 8674.116211\n",
      "Train Epoch: 260 [768/994 (75%)]\tLoss: 8670.812500\n",
      "Train Epoch: 260 [686/994 (88%)]\tLoss: 8661.174745\n",
      "====> Epoch: 260 Average loss: 8672.9232\n",
      "====> Test set loss: 8672.5920\n",
      "Train Epoch: 270 [0/994 (0%)]\tLoss: 8672.123047\n",
      "Train Epoch: 270 [128/994 (12%)]\tLoss: 8674.080078\n",
      "Train Epoch: 270 [256/994 (25%)]\tLoss: 8671.465820\n",
      "Train Epoch: 270 [384/994 (38%)]\tLoss: 8669.347656\n",
      "Train Epoch: 270 [512/994 (50%)]\tLoss: 8695.731445\n",
      "Train Epoch: 270 [640/994 (62%)]\tLoss: 8680.306641\n",
      "Train Epoch: 270 [768/994 (75%)]\tLoss: 8659.722656\n",
      "Train Epoch: 270 [686/994 (88%)]\tLoss: 8667.079082\n",
      "====> Epoch: 270 Average loss: 8673.9328\n",
      "====> Test set loss: 8674.6767\n",
      "Train Epoch: 280 [0/994 (0%)]\tLoss: 8673.951172\n",
      "Train Epoch: 280 [128/994 (12%)]\tLoss: 8648.280273\n",
      "Train Epoch: 280 [256/994 (25%)]\tLoss: 8663.961914\n",
      "Train Epoch: 280 [384/994 (38%)]\tLoss: 8699.575195\n",
      "Train Epoch: 280 [512/994 (50%)]\tLoss: 8678.519531\n",
      "Train Epoch: 280 [640/994 (62%)]\tLoss: 8669.732422\n",
      "Train Epoch: 280 [768/994 (75%)]\tLoss: 8672.066406\n",
      "Train Epoch: 280 [686/994 (88%)]\tLoss: 8673.456633\n",
      "====> Epoch: 280 Average loss: 8672.4123\n",
      "====> Test set loss: 8672.4555\n",
      "Train Epoch: 290 [0/994 (0%)]\tLoss: 8667.203125\n",
      "Train Epoch: 290 [128/994 (12%)]\tLoss: 8665.411133\n",
      "Train Epoch: 290 [256/994 (25%)]\tLoss: 8686.233398\n",
      "Train Epoch: 290 [384/994 (38%)]\tLoss: 8669.435547\n",
      "Train Epoch: 290 [512/994 (50%)]\tLoss: 8670.665039\n",
      "Train Epoch: 290 [640/994 (62%)]\tLoss: 8676.917969\n",
      "Train Epoch: 290 [768/994 (75%)]\tLoss: 8680.557617\n",
      "Train Epoch: 290 [686/994 (88%)]\tLoss: 8670.723214\n",
      "====> Epoch: 290 Average loss: 8673.4740\n",
      "====> Test set loss: 8671.9448\n",
      "Train Epoch: 300 [0/994 (0%)]\tLoss: 8675.294922\n",
      "Train Epoch: 300 [128/994 (12%)]\tLoss: 8696.333984\n",
      "Train Epoch: 300 [256/994 (25%)]\tLoss: 8654.796875\n",
      "Train Epoch: 300 [384/994 (38%)]\tLoss: 8674.137695\n",
      "Train Epoch: 300 [512/994 (50%)]\tLoss: 8652.438477\n",
      "Train Epoch: 300 [640/994 (62%)]\tLoss: 8664.311523\n",
      "Train Epoch: 300 [768/994 (75%)]\tLoss: 8676.878906\n",
      "Train Epoch: 300 [686/994 (88%)]\tLoss: 8671.637755\n",
      "====> Epoch: 300 Average loss: 8670.7013\n",
      "====> Test set loss: 8669.6859\n",
      "Train Epoch: 310 [0/994 (0%)]\tLoss: 8672.094727\n",
      "Train Epoch: 310 [128/994 (12%)]\tLoss: 8681.800781\n",
      "Train Epoch: 310 [256/994 (25%)]\tLoss: 8669.531250\n",
      "Train Epoch: 310 [384/994 (38%)]\tLoss: 8674.784180\n",
      "Train Epoch: 310 [512/994 (50%)]\tLoss: 8667.594727\n",
      "Train Epoch: 310 [640/994 (62%)]\tLoss: 8669.182617\n",
      "Train Epoch: 310 [768/994 (75%)]\tLoss: 8659.732422\n",
      "Train Epoch: 310 [686/994 (88%)]\tLoss: 8677.855867\n",
      "====> Epoch: 310 Average loss: 8671.3824\n",
      "====> Test set loss: 8669.4108\n",
      "Train Epoch: 320 [0/994 (0%)]\tLoss: 8675.648438\n",
      "Train Epoch: 320 [128/994 (12%)]\tLoss: 8678.484375\n",
      "Train Epoch: 320 [256/994 (25%)]\tLoss: 8668.550781\n",
      "Train Epoch: 320 [384/994 (38%)]\tLoss: 8668.880859\n",
      "Train Epoch: 320 [512/994 (50%)]\tLoss: 8675.051758\n",
      "Train Epoch: 320 [640/994 (62%)]\tLoss: 8658.214844\n",
      "Train Epoch: 320 [768/994 (75%)]\tLoss: 8665.023438\n",
      "Train Epoch: 320 [686/994 (88%)]\tLoss: 8670.715561\n",
      "====> Epoch: 320 Average loss: 8670.0518\n",
      "====> Test set loss: 8668.7145\n",
      "Train Epoch: 330 [0/994 (0%)]\tLoss: 8676.654297\n",
      "Train Epoch: 330 [128/994 (12%)]\tLoss: 8650.751953\n",
      "Train Epoch: 330 [256/994 (25%)]\tLoss: 8650.835938\n",
      "Train Epoch: 330 [384/994 (38%)]\tLoss: 8668.698242\n",
      "Train Epoch: 330 [512/994 (50%)]\tLoss: 8689.091797\n",
      "Train Epoch: 330 [640/994 (62%)]\tLoss: 8687.370117\n",
      "Train Epoch: 330 [768/994 (75%)]\tLoss: 8675.630859\n",
      "Train Epoch: 330 [686/994 (88%)]\tLoss: 8663.550383\n",
      "====> Epoch: 330 Average loss: 8670.5274\n",
      "====> Test set loss: 8669.7128\n",
      "Train Epoch: 340 [0/994 (0%)]\tLoss: 8673.178711\n",
      "Train Epoch: 340 [128/994 (12%)]\tLoss: 8685.312500\n",
      "Train Epoch: 340 [256/994 (25%)]\tLoss: 8675.073242\n",
      "Train Epoch: 340 [384/994 (38%)]\tLoss: 8669.021484\n",
      "Train Epoch: 340 [512/994 (50%)]\tLoss: 8667.406250\n",
      "Train Epoch: 340 [640/994 (62%)]\tLoss: 8669.094727\n",
      "Train Epoch: 340 [768/994 (75%)]\tLoss: 8668.440430\n",
      "Train Epoch: 340 [686/994 (88%)]\tLoss: 8645.949617\n",
      "====> Epoch: 340 Average loss: 8669.8859\n",
      "====> Test set loss: 8668.3858\n",
      "Train Epoch: 350 [0/994 (0%)]\tLoss: 8675.142578\n",
      "Train Epoch: 350 [128/994 (12%)]\tLoss: 8675.097656\n",
      "Train Epoch: 350 [256/994 (25%)]\tLoss: 8670.479492\n",
      "Train Epoch: 350 [384/994 (38%)]\tLoss: 8664.865234\n",
      "Train Epoch: 350 [512/994 (50%)]\tLoss: 8667.468750\n",
      "Train Epoch: 350 [640/994 (62%)]\tLoss: 8657.211914\n",
      "Train Epoch: 350 [768/994 (75%)]\tLoss: 8661.041992\n",
      "Train Epoch: 350 [686/994 (88%)]\tLoss: 8683.718112\n",
      "====> Epoch: 350 Average loss: 8668.9454\n",
      "====> Test set loss: 8667.4973\n",
      "Train Epoch: 360 [0/994 (0%)]\tLoss: 8689.517578\n",
      "Train Epoch: 360 [128/994 (12%)]\tLoss: 8661.580078\n",
      "Train Epoch: 360 [256/994 (25%)]\tLoss: 8654.904297\n",
      "Train Epoch: 360 [384/994 (38%)]\tLoss: 8659.151367\n",
      "Train Epoch: 360 [512/994 (50%)]\tLoss: 8652.708008\n",
      "Train Epoch: 360 [640/994 (62%)]\tLoss: 8678.229492\n",
      "Train Epoch: 360 [768/994 (75%)]\tLoss: 8679.479492\n",
      "Train Epoch: 360 [686/994 (88%)]\tLoss: 8665.680485\n",
      "====> Epoch: 360 Average loss: 8667.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 8667.7780\n",
      "Train Epoch: 370 [0/994 (0%)]\tLoss: 8677.730469\n",
      "Train Epoch: 370 [128/994 (12%)]\tLoss: 8685.972656\n",
      "Train Epoch: 370 [256/994 (25%)]\tLoss: 8678.284180\n",
      "Train Epoch: 370 [384/994 (38%)]\tLoss: 8674.279297\n",
      "Train Epoch: 370 [512/994 (50%)]\tLoss: 8671.650391\n",
      "Train Epoch: 370 [640/994 (62%)]\tLoss: 8663.050781\n",
      "Train Epoch: 370 [768/994 (75%)]\tLoss: 8654.585938\n",
      "Train Epoch: 370 [686/994 (88%)]\tLoss: 8658.141582\n",
      "====> Epoch: 370 Average loss: 8670.8338\n",
      "====> Test set loss: 8669.9780\n",
      "Train Epoch: 380 [0/994 (0%)]\tLoss: 8662.584961\n",
      "Train Epoch: 380 [128/994 (12%)]\tLoss: 8680.928711\n",
      "Train Epoch: 380 [256/994 (25%)]\tLoss: 8679.944336\n",
      "Train Epoch: 380 [384/994 (38%)]\tLoss: 8668.985352\n",
      "Train Epoch: 380 [512/994 (50%)]\tLoss: 8659.825195\n",
      "Train Epoch: 380 [640/994 (62%)]\tLoss: 8663.745117\n",
      "Train Epoch: 380 [768/994 (75%)]\tLoss: 8665.621094\n",
      "Train Epoch: 380 [686/994 (88%)]\tLoss: 8659.862883\n",
      "====> Epoch: 380 Average loss: 8667.9234\n",
      "====> Test set loss: 8666.7232\n",
      "Train Epoch: 390 [0/994 (0%)]\tLoss: 8650.800781\n",
      "Train Epoch: 390 [128/994 (12%)]\tLoss: 8667.755859\n",
      "Train Epoch: 390 [256/994 (25%)]\tLoss: 8675.345703\n",
      "Train Epoch: 390 [384/994 (38%)]\tLoss: 8671.687500\n",
      "Train Epoch: 390 [512/994 (50%)]\tLoss: 8657.041992\n",
      "Train Epoch: 390 [640/994 (62%)]\tLoss: 8686.502930\n",
      "Train Epoch: 390 [768/994 (75%)]\tLoss: 8654.284180\n",
      "Train Epoch: 390 [686/994 (88%)]\tLoss: 8680.371173\n",
      "====> Epoch: 390 Average loss: 8667.5996\n",
      "====> Test set loss: 8666.5855\n",
      "Train Epoch: 400 [0/994 (0%)]\tLoss: 8671.944336\n",
      "Train Epoch: 400 [128/994 (12%)]\tLoss: 8671.617188\n",
      "Train Epoch: 400 [256/994 (25%)]\tLoss: 8670.493164\n",
      "Train Epoch: 400 [384/994 (38%)]\tLoss: 8665.185547\n",
      "Train Epoch: 400 [512/994 (50%)]\tLoss: 8672.012695\n",
      "Train Epoch: 400 [640/994 (62%)]\tLoss: 8653.763672\n",
      "Train Epoch: 400 [768/994 (75%)]\tLoss: 8663.413086\n",
      "Train Epoch: 400 [686/994 (88%)]\tLoss: 8673.661990\n",
      "====> Epoch: 400 Average loss: 8667.5834\n",
      "====> Test set loss: 8665.5265\n",
      "Train Epoch: 410 [0/994 (0%)]\tLoss: 8664.808594\n",
      "Train Epoch: 410 [128/994 (12%)]\tLoss: 8665.737305\n",
      "Train Epoch: 410 [256/994 (25%)]\tLoss: 8675.904297\n",
      "Train Epoch: 410 [384/994 (38%)]\tLoss: 8679.845703\n",
      "Train Epoch: 410 [512/994 (50%)]\tLoss: 8649.769531\n",
      "Train Epoch: 410 [640/994 (62%)]\tLoss: 8661.605469\n",
      "Train Epoch: 410 [768/994 (75%)]\tLoss: 8669.526367\n",
      "Train Epoch: 410 [686/994 (88%)]\tLoss: 8665.603954\n",
      "====> Epoch: 410 Average loss: 8666.6302\n",
      "====> Test set loss: 8664.9383\n",
      "Train Epoch: 420 [0/994 (0%)]\tLoss: 8667.434570\n",
      "Train Epoch: 420 [128/994 (12%)]\tLoss: 8701.603516\n",
      "Train Epoch: 420 [256/994 (25%)]\tLoss: 8669.016602\n",
      "Train Epoch: 420 [384/994 (38%)]\tLoss: 8655.399414\n",
      "Train Epoch: 420 [512/994 (50%)]\tLoss: 8664.239258\n",
      "Train Epoch: 420 [640/994 (62%)]\tLoss: 8670.320312\n",
      "Train Epoch: 420 [768/994 (75%)]\tLoss: 8663.502930\n",
      "Train Epoch: 420 [686/994 (88%)]\tLoss: 8676.424107\n",
      "====> Epoch: 420 Average loss: 8670.8287\n",
      "====> Test set loss: 8672.7044\n",
      "Train Epoch: 430 [0/994 (0%)]\tLoss: 8654.184570\n",
      "Train Epoch: 430 [128/994 (12%)]\tLoss: 8657.378906\n",
      "Train Epoch: 430 [256/994 (25%)]\tLoss: 8672.502930\n",
      "Train Epoch: 430 [384/994 (38%)]\tLoss: 8671.572266\n",
      "Train Epoch: 430 [512/994 (50%)]\tLoss: 8680.583984\n",
      "Train Epoch: 430 [640/994 (62%)]\tLoss: 8660.459961\n",
      "Train Epoch: 430 [768/994 (75%)]\tLoss: 8672.046875\n",
      "Train Epoch: 430 [686/994 (88%)]\tLoss: 8655.330995\n",
      "====> Epoch: 430 Average loss: 8665.8147\n",
      "====> Test set loss: 8666.4168\n",
      "Train Epoch: 440 [0/994 (0%)]\tLoss: 8654.502930\n",
      "Train Epoch: 440 [128/994 (12%)]\tLoss: 8673.763672\n",
      "Train Epoch: 440 [256/994 (25%)]\tLoss: 8664.005859\n",
      "Train Epoch: 440 [384/994 (38%)]\tLoss: 8659.070312\n",
      "Train Epoch: 440 [512/994 (50%)]\tLoss: 8657.897461\n",
      "Train Epoch: 440 [640/994 (62%)]\tLoss: 8679.702148\n",
      "Train Epoch: 440 [768/994 (75%)]\tLoss: 8671.112305\n",
      "Train Epoch: 440 [686/994 (88%)]\tLoss: 8676.508291\n",
      "====> Epoch: 440 Average loss: 8666.7855\n",
      "====> Test set loss: 8666.8983\n",
      "Train Epoch: 450 [0/994 (0%)]\tLoss: 8661.755859\n",
      "Train Epoch: 450 [128/994 (12%)]\tLoss: 8662.228516\n",
      "Train Epoch: 450 [256/994 (25%)]\tLoss: 8676.663086\n",
      "Train Epoch: 450 [384/994 (38%)]\tLoss: 8665.790039\n",
      "Train Epoch: 450 [512/994 (50%)]\tLoss: 8664.912109\n",
      "Train Epoch: 450 [640/994 (62%)]\tLoss: 8661.855469\n",
      "Train Epoch: 450 [768/994 (75%)]\tLoss: 8668.667969\n",
      "Train Epoch: 450 [686/994 (88%)]\tLoss: 8671.657526\n",
      "====> Epoch: 450 Average loss: 8666.5414\n",
      "====> Test set loss: 8664.6957\n",
      "Train Epoch: 460 [0/994 (0%)]\tLoss: 8660.826172\n",
      "Train Epoch: 460 [128/994 (12%)]\tLoss: 8682.354492\n",
      "Train Epoch: 460 [256/994 (25%)]\tLoss: 8668.507812\n",
      "Train Epoch: 460 [384/994 (38%)]\tLoss: 8657.525391\n",
      "Train Epoch: 460 [512/994 (50%)]\tLoss: 8672.047852\n",
      "Train Epoch: 460 [640/994 (62%)]\tLoss: 8661.146484\n",
      "Train Epoch: 460 [768/994 (75%)]\tLoss: 8660.253906\n",
      "Train Epoch: 460 [686/994 (88%)]\tLoss: 8653.218112\n",
      "====> Epoch: 460 Average loss: 8664.8251\n",
      "====> Test set loss: 8665.1739\n",
      "Train Epoch: 470 [0/994 (0%)]\tLoss: 8650.039062\n",
      "Train Epoch: 470 [128/994 (12%)]\tLoss: 8674.929688\n",
      "Train Epoch: 470 [256/994 (25%)]\tLoss: 8667.380859\n",
      "Train Epoch: 470 [384/994 (38%)]\tLoss: 8663.156250\n",
      "Train Epoch: 470 [512/994 (50%)]\tLoss: 8663.987305\n",
      "Train Epoch: 470 [640/994 (62%)]\tLoss: 8673.767578\n",
      "Train Epoch: 470 [768/994 (75%)]\tLoss: 8655.573242\n",
      "Train Epoch: 470 [686/994 (88%)]\tLoss: 8658.325893\n",
      "====> Epoch: 470 Average loss: 8663.5480\n",
      "====> Test set loss: 8662.6569\n",
      "Train Epoch: 480 [0/994 (0%)]\tLoss: 8647.483398\n",
      "Train Epoch: 480 [128/994 (12%)]\tLoss: 8667.675781\n",
      "Train Epoch: 480 [256/994 (25%)]\tLoss: 8672.611328\n",
      "Train Epoch: 480 [384/994 (38%)]\tLoss: 8672.378906\n",
      "Train Epoch: 480 [512/994 (50%)]\tLoss: 8666.966797\n",
      "Train Epoch: 480 [640/994 (62%)]\tLoss: 8652.926758\n",
      "Train Epoch: 480 [768/994 (75%)]\tLoss: 8657.194336\n",
      "Train Epoch: 480 [686/994 (88%)]\tLoss: 8665.514031\n",
      "====> Epoch: 480 Average loss: 8662.7633\n",
      "====> Test set loss: 8661.9802\n",
      "Train Epoch: 490 [0/994 (0%)]\tLoss: 8657.748047\n",
      "Train Epoch: 490 [128/994 (12%)]\tLoss: 8658.867188\n",
      "Train Epoch: 490 [256/994 (25%)]\tLoss: 8661.172852\n",
      "Train Epoch: 490 [384/994 (38%)]\tLoss: 8660.398438\n",
      "Train Epoch: 490 [512/994 (50%)]\tLoss: 8687.532227\n",
      "Train Epoch: 490 [640/994 (62%)]\tLoss: 8672.735352\n",
      "Train Epoch: 490 [768/994 (75%)]\tLoss: 8642.558594\n",
      "Train Epoch: 490 [686/994 (88%)]\tLoss: 8667.051658\n",
      "====> Epoch: 490 Average loss: 8663.4011\n",
      "====> Test set loss: 8662.8893\n",
      "Train Epoch: 500 [0/994 (0%)]\tLoss: 8648.399414\n",
      "Train Epoch: 500 [128/994 (12%)]\tLoss: 8663.027344\n",
      "Train Epoch: 500 [256/994 (25%)]\tLoss: 8651.997070\n",
      "Train Epoch: 500 [384/994 (38%)]\tLoss: 8647.703125\n",
      "Train Epoch: 500 [512/994 (50%)]\tLoss: 8672.732422\n",
      "Train Epoch: 500 [640/994 (62%)]\tLoss: 8675.235352\n",
      "Train Epoch: 500 [768/994 (75%)]\tLoss: 8677.223633\n",
      "Train Epoch: 500 [686/994 (88%)]\tLoss: 8676.802934\n",
      "====> Epoch: 500 Average loss: 8663.7580\n",
      "====> Test set loss: 8663.0009\n",
      "Train Epoch: 510 [0/994 (0%)]\tLoss: 8658.483398\n",
      "Train Epoch: 510 [128/994 (12%)]\tLoss: 8653.436523\n",
      "Train Epoch: 510 [256/994 (25%)]\tLoss: 8657.838867\n",
      "Train Epoch: 510 [384/994 (38%)]\tLoss: 8658.054688\n",
      "Train Epoch: 510 [512/994 (50%)]\tLoss: 8664.075195\n",
      "Train Epoch: 510 [640/994 (62%)]\tLoss: 8669.421875\n",
      "Train Epoch: 510 [768/994 (75%)]\tLoss: 8659.114258\n",
      "Train Epoch: 510 [686/994 (88%)]\tLoss: 8673.469388\n",
      "====> Epoch: 510 Average loss: 8661.3827\n",
      "====> Test set loss: 8660.5861\n",
      "Train Epoch: 520 [0/994 (0%)]\tLoss: 8670.895508\n",
      "Train Epoch: 520 [128/994 (12%)]\tLoss: 8669.202148\n",
      "Train Epoch: 520 [256/994 (25%)]\tLoss: 8663.028320\n",
      "Train Epoch: 520 [384/994 (38%)]\tLoss: 8652.223633\n",
      "Train Epoch: 520 [512/994 (50%)]\tLoss: 8669.764648\n",
      "Train Epoch: 520 [640/994 (62%)]\tLoss: 8653.014648\n",
      "Train Epoch: 520 [768/994 (75%)]\tLoss: 8667.478516\n",
      "Train Epoch: 520 [686/994 (88%)]\tLoss: 8660.150510\n",
      "====> Epoch: 520 Average loss: 8663.3124\n",
      "====> Test set loss: 8664.5700\n",
      "Train Epoch: 530 [0/994 (0%)]\tLoss: 8664.333984\n",
      "Train Epoch: 530 [128/994 (12%)]\tLoss: 8656.582031\n",
      "Train Epoch: 530 [256/994 (25%)]\tLoss: 8665.471680\n",
      "Train Epoch: 530 [384/994 (38%)]\tLoss: 8653.921875\n",
      "Train Epoch: 530 [512/994 (50%)]\tLoss: 8654.231445\n",
      "Train Epoch: 530 [640/994 (62%)]\tLoss: 8675.715820\n",
      "Train Epoch: 530 [768/994 (75%)]\tLoss: 8657.579102\n",
      "Train Epoch: 530 [686/994 (88%)]\tLoss: 8660.997449\n",
      "====> Epoch: 530 Average loss: 8661.1074\n",
      "====> Test set loss: 8661.7496\n",
      "Train Epoch: 540 [0/994 (0%)]\tLoss: 8676.421875\n",
      "Train Epoch: 540 [128/994 (12%)]\tLoss: 8662.400391\n",
      "Train Epoch: 540 [256/994 (25%)]\tLoss: 8678.980469\n",
      "Train Epoch: 540 [384/994 (38%)]\tLoss: 8675.443359\n",
      "Train Epoch: 540 [512/994 (50%)]\tLoss: 8665.804688\n",
      "Train Epoch: 540 [640/994 (62%)]\tLoss: 8657.342773\n",
      "Train Epoch: 540 [768/994 (75%)]\tLoss: 8668.719727\n",
      "Train Epoch: 540 [686/994 (88%)]\tLoss: 8650.114796\n",
      "====> Epoch: 540 Average loss: 8667.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 8668.8804\n",
      "Train Epoch: 550 [0/994 (0%)]\tLoss: 8648.820312\n",
      "Train Epoch: 550 [128/994 (12%)]\tLoss: 8657.298828\n",
      "Train Epoch: 550 [256/994 (25%)]\tLoss: 8669.317383\n",
      "Train Epoch: 550 [384/994 (38%)]\tLoss: 8649.674805\n",
      "Train Epoch: 550 [512/994 (50%)]\tLoss: 8686.325195\n",
      "Train Epoch: 550 [640/994 (62%)]\tLoss: 8660.325195\n",
      "Train Epoch: 550 [768/994 (75%)]\tLoss: 8671.465820\n",
      "Train Epoch: 550 [686/994 (88%)]\tLoss: 8647.066327\n",
      "====> Epoch: 550 Average loss: 8661.7159\n",
      "====> Test set loss: 8659.7987\n",
      "Train Epoch: 560 [0/994 (0%)]\tLoss: 8660.707031\n",
      "Train Epoch: 560 [128/994 (12%)]\tLoss: 8668.515625\n",
      "Train Epoch: 560 [256/994 (25%)]\tLoss: 8657.032227\n",
      "Train Epoch: 560 [384/994 (38%)]\tLoss: 8660.536133\n",
      "Train Epoch: 560 [512/994 (50%)]\tLoss: 8650.877930\n",
      "Train Epoch: 560 [640/994 (62%)]\tLoss: 8665.796875\n",
      "Train Epoch: 560 [768/994 (75%)]\tLoss: 8656.810547\n",
      "Train Epoch: 560 [686/994 (88%)]\tLoss: 8677.107143\n",
      "====> Epoch: 560 Average loss: 8661.7222\n",
      "====> Test set loss: 8663.0833\n",
      "Train Epoch: 570 [0/994 (0%)]\tLoss: 8671.726562\n",
      "Train Epoch: 570 [128/994 (12%)]\tLoss: 8664.009766\n",
      "Train Epoch: 570 [256/994 (25%)]\tLoss: 8663.896484\n",
      "Train Epoch: 570 [384/994 (38%)]\tLoss: 8681.856445\n",
      "Train Epoch: 570 [512/994 (50%)]\tLoss: 8663.704102\n",
      "Train Epoch: 570 [640/994 (62%)]\tLoss: 8664.715820\n",
      "Train Epoch: 570 [768/994 (75%)]\tLoss: 8663.855469\n",
      "Train Epoch: 570 [686/994 (88%)]\tLoss: 8666.417092\n",
      "====> Epoch: 570 Average loss: 8667.5561\n",
      "====> Test set loss: 8663.6306\n",
      "Train Epoch: 580 [0/994 (0%)]\tLoss: 8666.234375\n",
      "Train Epoch: 580 [128/994 (12%)]\tLoss: 8667.308594\n",
      "Train Epoch: 580 [256/994 (25%)]\tLoss: 8670.880859\n",
      "Train Epoch: 580 [384/994 (38%)]\tLoss: 8645.925781\n",
      "Train Epoch: 580 [512/994 (50%)]\tLoss: 8651.564453\n",
      "Train Epoch: 580 [640/994 (62%)]\tLoss: 8663.428711\n",
      "Train Epoch: 580 [768/994 (75%)]\tLoss: 8657.114258\n",
      "Train Epoch: 580 [686/994 (88%)]\tLoss: 8654.717474\n",
      "====> Epoch: 580 Average loss: 8659.7956\n",
      "====> Test set loss: 8658.5999\n",
      "Train Epoch: 590 [0/994 (0%)]\tLoss: 8659.225586\n",
      "Train Epoch: 590 [128/994 (12%)]\tLoss: 8670.266602\n",
      "Train Epoch: 590 [256/994 (25%)]\tLoss: 8666.543945\n",
      "Train Epoch: 590 [384/994 (38%)]\tLoss: 8668.176758\n",
      "Train Epoch: 590 [512/994 (50%)]\tLoss: 8643.797852\n",
      "Train Epoch: 590 [640/994 (62%)]\tLoss: 8643.831055\n",
      "Train Epoch: 590 [768/994 (75%)]\tLoss: 8667.866211\n",
      "Train Epoch: 590 [686/994 (88%)]\tLoss: 8662.127551\n",
      "====> Epoch: 590 Average loss: 8660.1722\n",
      "====> Test set loss: 8658.2078\n",
      "Train Epoch: 600 [0/994 (0%)]\tLoss: 8669.435547\n",
      "Train Epoch: 600 [128/994 (12%)]\tLoss: 8667.121094\n",
      "Train Epoch: 600 [256/994 (25%)]\tLoss: 8657.524414\n",
      "Train Epoch: 600 [384/994 (38%)]\tLoss: 8638.442383\n",
      "Train Epoch: 600 [512/994 (50%)]\tLoss: 8654.713867\n",
      "Train Epoch: 600 [640/994 (62%)]\tLoss: 8659.189453\n",
      "Train Epoch: 600 [768/994 (75%)]\tLoss: 8671.378906\n",
      "Train Epoch: 600 [686/994 (88%)]\tLoss: 8657.458546\n",
      "====> Epoch: 600 Average loss: 8659.4669\n",
      "====> Test set loss: 8659.2026\n",
      "Train Epoch: 610 [0/994 (0%)]\tLoss: 8653.187500\n",
      "Train Epoch: 610 [128/994 (12%)]\tLoss: 8655.827148\n",
      "Train Epoch: 610 [256/994 (25%)]\tLoss: 8661.801758\n",
      "Train Epoch: 610 [384/994 (38%)]\tLoss: 8657.021484\n",
      "Train Epoch: 610 [512/994 (50%)]\tLoss: 8660.901367\n",
      "Train Epoch: 610 [640/994 (62%)]\tLoss: 8677.720703\n",
      "Train Epoch: 610 [768/994 (75%)]\tLoss: 8661.144531\n",
      "Train Epoch: 610 [686/994 (88%)]\tLoss: 8659.080995\n",
      "====> Epoch: 610 Average loss: 8660.8886\n",
      "====> Test set loss: 8662.4134\n",
      "Train Epoch: 620 [0/994 (0%)]\tLoss: 8646.999023\n",
      "Train Epoch: 620 [128/994 (12%)]\tLoss: 8650.657227\n",
      "Train Epoch: 620 [256/994 (25%)]\tLoss: 8653.601562\n",
      "Train Epoch: 620 [384/994 (38%)]\tLoss: 8652.277344\n",
      "Train Epoch: 620 [512/994 (50%)]\tLoss: 8665.416016\n",
      "Train Epoch: 620 [640/994 (62%)]\tLoss: 8657.980469\n",
      "Train Epoch: 620 [768/994 (75%)]\tLoss: 8661.098633\n",
      "Train Epoch: 620 [686/994 (88%)]\tLoss: 8682.857781\n",
      "====> Epoch: 620 Average loss: 8658.1368\n",
      "====> Test set loss: 8656.7932\n",
      "Train Epoch: 630 [0/994 (0%)]\tLoss: 8635.671875\n",
      "Train Epoch: 630 [128/994 (12%)]\tLoss: 8648.676758\n",
      "Train Epoch: 630 [256/994 (25%)]\tLoss: 8657.589844\n",
      "Train Epoch: 630 [384/994 (38%)]\tLoss: 8650.392578\n",
      "Train Epoch: 630 [512/994 (50%)]\tLoss: 8663.954102\n",
      "Train Epoch: 630 [640/994 (62%)]\tLoss: 8668.086914\n",
      "Train Epoch: 630 [768/994 (75%)]\tLoss: 8675.710938\n",
      "Train Epoch: 630 [686/994 (88%)]\tLoss: 8667.011480\n",
      "====> Epoch: 630 Average loss: 8658.1265\n",
      "====> Test set loss: 8656.9310\n",
      "Train Epoch: 640 [0/994 (0%)]\tLoss: 8668.041016\n",
      "Train Epoch: 640 [128/994 (12%)]\tLoss: 8641.228516\n",
      "Train Epoch: 640 [256/994 (25%)]\tLoss: 8665.632812\n",
      "Train Epoch: 640 [384/994 (38%)]\tLoss: 8657.720703\n",
      "Train Epoch: 640 [512/994 (50%)]\tLoss: 8663.771484\n",
      "Train Epoch: 640 [640/994 (62%)]\tLoss: 8663.106445\n",
      "Train Epoch: 640 [768/994 (75%)]\tLoss: 8680.646484\n",
      "Train Epoch: 640 [686/994 (88%)]\tLoss: 8653.990434\n",
      "====> Epoch: 640 Average loss: 8662.0019\n",
      "====> Test set loss: 8659.1977\n",
      "Train Epoch: 650 [0/994 (0%)]\tLoss: 8657.773438\n",
      "Train Epoch: 650 [128/994 (12%)]\tLoss: 8666.521484\n",
      "Train Epoch: 650 [256/994 (25%)]\tLoss: 8657.913086\n",
      "Train Epoch: 650 [384/994 (38%)]\tLoss: 8662.465820\n",
      "Train Epoch: 650 [512/994 (50%)]\tLoss: 8656.062500\n",
      "Train Epoch: 650 [640/994 (62%)]\tLoss: 8667.057617\n",
      "Train Epoch: 650 [768/994 (75%)]\tLoss: 8642.547852\n",
      "Train Epoch: 650 [686/994 (88%)]\tLoss: 8657.275510\n",
      "====> Epoch: 650 Average loss: 8658.4877\n",
      "====> Test set loss: 8656.1644\n",
      "Train Epoch: 660 [0/994 (0%)]\tLoss: 8657.633789\n",
      "Train Epoch: 660 [128/994 (12%)]\tLoss: 8668.139648\n",
      "Train Epoch: 660 [256/994 (25%)]\tLoss: 8671.181641\n",
      "Train Epoch: 660 [384/994 (38%)]\tLoss: 8657.913086\n",
      "Train Epoch: 660 [512/994 (50%)]\tLoss: 8656.076172\n",
      "Train Epoch: 660 [640/994 (62%)]\tLoss: 8653.849609\n",
      "Train Epoch: 660 [768/994 (75%)]\tLoss: 8660.657227\n",
      "Train Epoch: 660 [686/994 (88%)]\tLoss: 8647.201531\n",
      "====> Epoch: 660 Average loss: 8659.4401\n",
      "====> Test set loss: 8662.4904\n",
      "Train Epoch: 670 [0/994 (0%)]\tLoss: 8660.253906\n",
      "Train Epoch: 670 [128/994 (12%)]\tLoss: 8661.774414\n",
      "Train Epoch: 670 [256/994 (25%)]\tLoss: 8667.912109\n",
      "Train Epoch: 670 [384/994 (38%)]\tLoss: 8670.826172\n",
      "Train Epoch: 670 [512/994 (50%)]\tLoss: 8648.668945\n",
      "Train Epoch: 670 [640/994 (62%)]\tLoss: 8650.316406\n",
      "Train Epoch: 670 [768/994 (75%)]\tLoss: 8638.836914\n",
      "Train Epoch: 670 [686/994 (88%)]\tLoss: 8665.492347\n",
      "====> Epoch: 670 Average loss: 8657.7843\n",
      "====> Test set loss: 8655.7230\n",
      "Train Epoch: 680 [0/994 (0%)]\tLoss: 8656.671875\n",
      "Train Epoch: 680 [128/994 (12%)]\tLoss: 8645.811523\n",
      "Train Epoch: 680 [256/994 (25%)]\tLoss: 8666.074219\n",
      "Train Epoch: 680 [384/994 (38%)]\tLoss: 8662.211914\n",
      "Train Epoch: 680 [512/994 (50%)]\tLoss: 8651.868164\n",
      "Train Epoch: 680 [640/994 (62%)]\tLoss: 8648.913086\n",
      "Train Epoch: 680 [768/994 (75%)]\tLoss: 8668.789062\n",
      "Train Epoch: 680 [686/994 (88%)]\tLoss: 8680.014031\n",
      "====> Epoch: 680 Average loss: 8659.4415\n",
      "====> Test set loss: 8655.4231\n",
      "Train Epoch: 690 [0/994 (0%)]\tLoss: 8659.695312\n",
      "Train Epoch: 690 [128/994 (12%)]\tLoss: 8653.916016\n",
      "Train Epoch: 690 [256/994 (25%)]\tLoss: 8663.785156\n",
      "Train Epoch: 690 [384/994 (38%)]\tLoss: 8659.694336\n",
      "Train Epoch: 690 [512/994 (50%)]\tLoss: 8657.557617\n",
      "Train Epoch: 690 [640/994 (62%)]\tLoss: 8643.822266\n",
      "Train Epoch: 690 [768/994 (75%)]\tLoss: 8657.600586\n",
      "Train Epoch: 690 [686/994 (88%)]\tLoss: 8651.325893\n",
      "====> Epoch: 690 Average loss: 8656.0634\n",
      "====> Test set loss: 8655.8024\n",
      "Train Epoch: 700 [0/994 (0%)]\tLoss: 8643.037109\n",
      "Train Epoch: 700 [128/994 (12%)]\tLoss: 8658.844727\n",
      "Train Epoch: 700 [256/994 (25%)]\tLoss: 8654.780273\n",
      "Train Epoch: 700 [384/994 (38%)]\tLoss: 8656.432617\n",
      "Train Epoch: 700 [512/994 (50%)]\tLoss: 8646.536133\n",
      "Train Epoch: 700 [640/994 (62%)]\tLoss: 8659.111328\n",
      "Train Epoch: 700 [768/994 (75%)]\tLoss: 8664.747070\n",
      "Train Epoch: 700 [686/994 (88%)]\tLoss: 8666.570153\n",
      "====> Epoch: 700 Average loss: 8655.9462\n",
      "====> Test set loss: 8654.6844\n",
      "Train Epoch: 710 [0/994 (0%)]\tLoss: 8652.158203\n",
      "Train Epoch: 710 [128/994 (12%)]\tLoss: 8654.663086\n",
      "Train Epoch: 710 [256/994 (25%)]\tLoss: 8654.589844\n",
      "Train Epoch: 710 [384/994 (38%)]\tLoss: 8669.128906\n",
      "Train Epoch: 710 [512/994 (50%)]\tLoss: 8647.927734\n",
      "Train Epoch: 710 [640/994 (62%)]\tLoss: 8662.638672\n",
      "Train Epoch: 710 [768/994 (75%)]\tLoss: 8655.973633\n",
      "Train Epoch: 710 [686/994 (88%)]\tLoss: 8653.165179\n",
      "====> Epoch: 710 Average loss: 8656.3747\n",
      "====> Test set loss: 8655.0454\n",
      "Train Epoch: 720 [0/994 (0%)]\tLoss: 8645.469727\n",
      "Train Epoch: 720 [128/994 (12%)]\tLoss: 8659.096680\n",
      "Train Epoch: 720 [256/994 (25%)]\tLoss: 8652.122070\n",
      "Train Epoch: 720 [384/994 (38%)]\tLoss: 8654.717773\n",
      "Train Epoch: 720 [512/994 (50%)]\tLoss: 8651.368164\n",
      "Train Epoch: 720 [640/994 (62%)]\tLoss: 8675.942383\n",
      "Train Epoch: 720 [768/994 (75%)]\tLoss: 8652.061523\n",
      "Train Epoch: 720 [686/994 (88%)]\tLoss: 8649.692602\n",
      "====> Epoch: 720 Average loss: 8655.2208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 8654.5846\n",
      "Train Epoch: 730 [0/994 (0%)]\tLoss: 8646.878906\n",
      "Train Epoch: 730 [128/994 (12%)]\tLoss: 8664.060547\n",
      "Train Epoch: 730 [256/994 (25%)]\tLoss: 8658.542969\n",
      "Train Epoch: 730 [384/994 (38%)]\tLoss: 8651.935547\n",
      "Train Epoch: 730 [512/994 (50%)]\tLoss: 8655.420898\n",
      "Train Epoch: 730 [640/994 (62%)]\tLoss: 8658.356445\n",
      "Train Epoch: 730 [768/994 (75%)]\tLoss: 8655.960938\n",
      "Train Epoch: 730 [686/994 (88%)]\tLoss: 8655.433036\n",
      "====> Epoch: 730 Average loss: 8655.8355\n",
      "====> Test set loss: 8655.5553\n",
      "Train Epoch: 740 [0/994 (0%)]\tLoss: 8659.518555\n",
      "Train Epoch: 740 [128/994 (12%)]\tLoss: 8645.993164\n",
      "Train Epoch: 740 [256/994 (25%)]\tLoss: 8641.267578\n",
      "Train Epoch: 740 [384/994 (38%)]\tLoss: 8641.820312\n",
      "Train Epoch: 740 [512/994 (50%)]\tLoss: 8659.485352\n",
      "Train Epoch: 740 [640/994 (62%)]\tLoss: 8677.287109\n",
      "Train Epoch: 740 [768/994 (75%)]\tLoss: 8662.480469\n",
      "Train Epoch: 740 [686/994 (88%)]\tLoss: 8653.311224\n",
      "====> Epoch: 740 Average loss: 8655.2008\n",
      "====> Test set loss: 8654.6736\n",
      "Train Epoch: 750 [0/994 (0%)]\tLoss: 8655.509766\n",
      "Train Epoch: 750 [128/994 (12%)]\tLoss: 8656.223633\n",
      "Train Epoch: 750 [256/994 (25%)]\tLoss: 8642.093750\n",
      "Train Epoch: 750 [384/994 (38%)]\tLoss: 8652.034180\n",
      "Train Epoch: 750 [512/994 (50%)]\tLoss: 8649.492188\n",
      "Train Epoch: 750 [640/994 (62%)]\tLoss: 8664.388672\n",
      "Train Epoch: 750 [768/994 (75%)]\tLoss: 8666.187500\n",
      "Train Epoch: 750 [686/994 (88%)]\tLoss: 8655.558036\n",
      "====> Epoch: 750 Average loss: 8655.1747\n",
      "====> Test set loss: 8654.1957\n",
      "Train Epoch: 760 [0/994 (0%)]\tLoss: 8653.109375\n",
      "Train Epoch: 760 [128/994 (12%)]\tLoss: 8669.440430\n",
      "Train Epoch: 760 [256/994 (25%)]\tLoss: 8634.086914\n",
      "Train Epoch: 760 [384/994 (38%)]\tLoss: 8663.053711\n",
      "Train Epoch: 760 [512/994 (50%)]\tLoss: 8664.071289\n",
      "Train Epoch: 760 [640/994 (62%)]\tLoss: 8663.479492\n",
      "Train Epoch: 760 [768/994 (75%)]\tLoss: 8650.741211\n",
      "Train Epoch: 760 [686/994 (88%)]\tLoss: 8659.656250\n",
      "====> Epoch: 760 Average loss: 8657.1308\n",
      "====> Test set loss: 8654.0233\n",
      "Train Epoch: 770 [0/994 (0%)]\tLoss: 8654.508789\n",
      "Train Epoch: 770 [128/994 (12%)]\tLoss: 8661.753906\n",
      "Train Epoch: 770 [256/994 (25%)]\tLoss: 8640.908203\n",
      "Train Epoch: 770 [384/994 (38%)]\tLoss: 8671.511719\n",
      "Train Epoch: 770 [512/994 (50%)]\tLoss: 8642.228516\n",
      "Train Epoch: 770 [640/994 (62%)]\tLoss: 8656.350586\n",
      "Train Epoch: 770 [768/994 (75%)]\tLoss: 8659.891602\n",
      "Train Epoch: 770 [686/994 (88%)]\tLoss: 8654.500638\n",
      "====> Epoch: 770 Average loss: 8655.2281\n",
      "====> Test set loss: 8655.5848\n",
      "Train Epoch: 780 [0/994 (0%)]\tLoss: 8653.862305\n",
      "Train Epoch: 780 [128/994 (12%)]\tLoss: 8658.393555\n",
      "Train Epoch: 780 [256/994 (25%)]\tLoss: 8649.344727\n",
      "Train Epoch: 780 [384/994 (38%)]\tLoss: 8654.143555\n",
      "Train Epoch: 780 [512/994 (50%)]\tLoss: 8649.000000\n",
      "Train Epoch: 780 [640/994 (62%)]\tLoss: 8669.661133\n",
      "Train Epoch: 780 [768/994 (75%)]\tLoss: 8658.947266\n",
      "Train Epoch: 780 [686/994 (88%)]\tLoss: 8624.729592\n",
      "====> Epoch: 780 Average loss: 8653.0912\n",
      "====> Test set loss: 8652.4242\n",
      "Train Epoch: 790 [0/994 (0%)]\tLoss: 8653.626953\n",
      "Train Epoch: 790 [128/994 (12%)]\tLoss: 8644.112305\n",
      "Train Epoch: 790 [256/994 (25%)]\tLoss: 8650.089844\n",
      "Train Epoch: 790 [384/994 (38%)]\tLoss: 8647.148438\n",
      "Train Epoch: 790 [512/994 (50%)]\tLoss: 8676.261719\n",
      "Train Epoch: 790 [640/994 (62%)]\tLoss: 8663.992188\n",
      "Train Epoch: 790 [768/994 (75%)]\tLoss: 8662.375977\n",
      "Train Epoch: 790 [686/994 (88%)]\tLoss: 8662.056122\n",
      "====> Epoch: 790 Average loss: 8657.3192\n",
      "====> Test set loss: 8658.4962\n",
      "Train Epoch: 800 [0/994 (0%)]\tLoss: 8653.770508\n",
      "Train Epoch: 800 [128/994 (12%)]\tLoss: 8649.038086\n",
      "Train Epoch: 800 [256/994 (25%)]\tLoss: 8646.641602\n",
      "Train Epoch: 800 [384/994 (38%)]\tLoss: 8654.433594\n",
      "Train Epoch: 800 [512/994 (50%)]\tLoss: 8662.471680\n",
      "Train Epoch: 800 [640/994 (62%)]\tLoss: 8664.081055\n",
      "Train Epoch: 800 [768/994 (75%)]\tLoss: 8656.639648\n",
      "Train Epoch: 800 [686/994 (88%)]\tLoss: 8637.597577\n",
      "====> Epoch: 800 Average loss: 8653.5516\n",
      "====> Test set loss: 8652.6161\n",
      "Train Epoch: 810 [0/994 (0%)]\tLoss: 8659.948242\n",
      "Train Epoch: 810 [128/994 (12%)]\tLoss: 8642.636719\n",
      "Train Epoch: 810 [256/994 (25%)]\tLoss: 8648.647461\n",
      "Train Epoch: 810 [384/994 (38%)]\tLoss: 8666.148438\n",
      "Train Epoch: 810 [512/994 (50%)]\tLoss: 8666.680664\n",
      "Train Epoch: 810 [640/994 (62%)]\tLoss: 8653.145508\n",
      "Train Epoch: 810 [768/994 (75%)]\tLoss: 8638.565430\n",
      "Train Epoch: 810 [686/994 (88%)]\tLoss: 8658.041454\n",
      "====> Epoch: 810 Average loss: 8654.1116\n",
      "====> Test set loss: 8656.3837\n",
      "Train Epoch: 820 [0/994 (0%)]\tLoss: 8641.708984\n",
      "Train Epoch: 820 [128/994 (12%)]\tLoss: 8654.263672\n",
      "Train Epoch: 820 [256/994 (25%)]\tLoss: 8647.371094\n",
      "Train Epoch: 820 [384/994 (38%)]\tLoss: 8670.443359\n",
      "Train Epoch: 820 [512/994 (50%)]\tLoss: 8666.986328\n",
      "Train Epoch: 820 [640/994 (62%)]\tLoss: 8647.172852\n",
      "Train Epoch: 820 [768/994 (75%)]\tLoss: 8643.670898\n",
      "Train Epoch: 820 [686/994 (88%)]\tLoss: 8654.657526\n",
      "====> Epoch: 820 Average loss: 8653.2429\n",
      "====> Test set loss: 8652.3119\n",
      "Train Epoch: 830 [0/994 (0%)]\tLoss: 8650.737305\n",
      "Train Epoch: 830 [128/994 (12%)]\tLoss: 8649.653320\n",
      "Train Epoch: 830 [256/994 (25%)]\tLoss: 8669.541016\n",
      "Train Epoch: 830 [384/994 (38%)]\tLoss: 8660.185547\n",
      "Train Epoch: 830 [512/994 (50%)]\tLoss: 8653.327148\n",
      "Train Epoch: 830 [640/994 (62%)]\tLoss: 8649.029297\n",
      "Train Epoch: 830 [768/994 (75%)]\tLoss: 8638.931641\n",
      "Train Epoch: 830 [686/994 (88%)]\tLoss: 8650.257653\n",
      "====> Epoch: 830 Average loss: 8652.7818\n",
      "====> Test set loss: 8651.2670\n",
      "Train Epoch: 840 [0/994 (0%)]\tLoss: 8653.204102\n",
      "Train Epoch: 840 [128/994 (12%)]\tLoss: 8658.797852\n",
      "Train Epoch: 840 [256/994 (25%)]\tLoss: 8646.873047\n",
      "Train Epoch: 840 [384/994 (38%)]\tLoss: 8632.429688\n",
      "Train Epoch: 840 [512/994 (50%)]\tLoss: 8658.916992\n",
      "Train Epoch: 840 [640/994 (62%)]\tLoss: 8656.616211\n",
      "Train Epoch: 840 [768/994 (75%)]\tLoss: 8653.632812\n",
      "Train Epoch: 840 [686/994 (88%)]\tLoss: 8668.821429\n",
      "====> Epoch: 840 Average loss: 8653.2040\n",
      "====> Test set loss: 8653.0148\n",
      "Train Epoch: 850 [0/994 (0%)]\tLoss: 8642.934570\n",
      "Train Epoch: 850 [128/994 (12%)]\tLoss: 8660.930664\n",
      "Train Epoch: 850 [256/994 (25%)]\tLoss: 8653.443359\n",
      "Train Epoch: 850 [384/994 (38%)]\tLoss: 8662.804688\n",
      "Train Epoch: 850 [512/994 (50%)]\tLoss: 8650.833984\n",
      "Train Epoch: 850 [640/994 (62%)]\tLoss: 8647.371094\n",
      "Train Epoch: 850 [768/994 (75%)]\tLoss: 8650.658203\n",
      "Train Epoch: 850 [686/994 (88%)]\tLoss: 8647.366709\n",
      "====> Epoch: 850 Average loss: 8652.1840\n",
      "====> Test set loss: 8652.7164\n",
      "Train Epoch: 860 [0/994 (0%)]\tLoss: 8649.415039\n",
      "Train Epoch: 860 [128/994 (12%)]\tLoss: 8658.912109\n",
      "Train Epoch: 860 [256/994 (25%)]\tLoss: 8654.541016\n",
      "Train Epoch: 860 [384/994 (38%)]\tLoss: 8630.397461\n",
      "Train Epoch: 860 [512/994 (50%)]\tLoss: 8651.040039\n",
      "Train Epoch: 860 [640/994 (62%)]\tLoss: 8649.646484\n",
      "Train Epoch: 860 [768/994 (75%)]\tLoss: 8658.916016\n",
      "Train Epoch: 860 [686/994 (88%)]\tLoss: 8662.696429\n",
      "====> Epoch: 860 Average loss: 8651.6211\n",
      "====> Test set loss: 8651.2232\n",
      "Train Epoch: 870 [0/994 (0%)]\tLoss: 8656.311523\n",
      "Train Epoch: 870 [128/994 (12%)]\tLoss: 8656.217773\n",
      "Train Epoch: 870 [256/994 (25%)]\tLoss: 8635.766602\n",
      "Train Epoch: 870 [384/994 (38%)]\tLoss: 8651.197266\n",
      "Train Epoch: 870 [512/994 (50%)]\tLoss: 8653.339844\n",
      "Train Epoch: 870 [640/994 (62%)]\tLoss: 8647.596680\n",
      "Train Epoch: 870 [768/994 (75%)]\tLoss: 8653.234375\n",
      "Train Epoch: 870 [686/994 (88%)]\tLoss: 8668.643495\n",
      "====> Epoch: 870 Average loss: 8652.3099\n",
      "====> Test set loss: 8652.6317\n",
      "Train Epoch: 880 [0/994 (0%)]\tLoss: 8651.887695\n",
      "Train Epoch: 880 [128/994 (12%)]\tLoss: 8649.941406\n",
      "Train Epoch: 880 [256/994 (25%)]\tLoss: 8659.554688\n",
      "Train Epoch: 880 [384/994 (38%)]\tLoss: 8651.775391\n",
      "Train Epoch: 880 [512/994 (50%)]\tLoss: 8652.432617\n",
      "Train Epoch: 880 [640/994 (62%)]\tLoss: 8661.503906\n",
      "Train Epoch: 880 [768/994 (75%)]\tLoss: 8640.642578\n",
      "Train Epoch: 880 [686/994 (88%)]\tLoss: 8653.327806\n",
      "====> Epoch: 880 Average loss: 8652.6123\n",
      "====> Test set loss: 8650.2479\n",
      "Train Epoch: 890 [0/994 (0%)]\tLoss: 8643.780273\n",
      "Train Epoch: 890 [128/994 (12%)]\tLoss: 8641.934570\n",
      "Train Epoch: 890 [256/994 (25%)]\tLoss: 8658.611328\n",
      "Train Epoch: 890 [384/994 (38%)]\tLoss: 8661.265625\n",
      "Train Epoch: 890 [512/994 (50%)]\tLoss: 8663.664062\n",
      "Train Epoch: 890 [640/994 (62%)]\tLoss: 8658.167969\n",
      "Train Epoch: 890 [768/994 (75%)]\tLoss: 8649.950195\n",
      "Train Epoch: 890 [686/994 (88%)]\tLoss: 8641.252551\n",
      "====> Epoch: 890 Average loss: 8652.6626\n",
      "====> Test set loss: 8651.8764\n",
      "Train Epoch: 900 [0/994 (0%)]\tLoss: 8653.523438\n",
      "Train Epoch: 900 [128/994 (12%)]\tLoss: 8647.984375\n",
      "Train Epoch: 900 [256/994 (25%)]\tLoss: 8649.702148\n",
      "Train Epoch: 900 [384/994 (38%)]\tLoss: 8661.735352\n",
      "Train Epoch: 900 [512/994 (50%)]\tLoss: 8642.832031\n",
      "Train Epoch: 900 [640/994 (62%)]\tLoss: 8642.908203\n",
      "Train Epoch: 900 [768/994 (75%)]\tLoss: 8661.990234\n",
      "Train Epoch: 900 [686/994 (88%)]\tLoss: 8653.153061\n",
      "====> Epoch: 900 Average loss: 8651.6856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 8650.7385\n",
      "Train Epoch: 910 [0/994 (0%)]\tLoss: 8645.694336\n",
      "Train Epoch: 910 [128/994 (12%)]\tLoss: 8648.983398\n",
      "Train Epoch: 910 [256/994 (25%)]\tLoss: 8642.826172\n",
      "Train Epoch: 910 [384/994 (38%)]\tLoss: 8649.105469\n",
      "Train Epoch: 910 [512/994 (50%)]\tLoss: 8657.480469\n",
      "Train Epoch: 910 [640/994 (62%)]\tLoss: 8648.833984\n",
      "Train Epoch: 910 [768/994 (75%)]\tLoss: 8669.442383\n",
      "Train Epoch: 910 [686/994 (88%)]\tLoss: 8654.973852\n",
      "====> Epoch: 910 Average loss: 8652.0828\n",
      "====> Test set loss: 8650.2860\n",
      "Train Epoch: 920 [0/994 (0%)]\tLoss: 8652.788086\n",
      "Train Epoch: 920 [128/994 (12%)]\tLoss: 8649.651367\n",
      "Train Epoch: 920 [256/994 (25%)]\tLoss: 8630.443359\n",
      "Train Epoch: 920 [384/994 (38%)]\tLoss: 8645.681641\n",
      "Train Epoch: 920 [512/994 (50%)]\tLoss: 8661.604492\n",
      "Train Epoch: 920 [640/994 (62%)]\tLoss: 8657.315430\n",
      "Train Epoch: 920 [768/994 (75%)]\tLoss: 8658.258789\n",
      "Train Epoch: 920 [686/994 (88%)]\tLoss: 8648.443240\n",
      "====> Epoch: 920 Average loss: 8650.5861\n",
      "====> Test set loss: 8649.8946\n",
      "Train Epoch: 930 [0/994 (0%)]\tLoss: 8649.609375\n",
      "Train Epoch: 930 [128/994 (12%)]\tLoss: 8635.897461\n",
      "Train Epoch: 930 [256/994 (25%)]\tLoss: 8640.357422\n",
      "Train Epoch: 930 [384/994 (38%)]\tLoss: 8649.586914\n",
      "Train Epoch: 930 [512/994 (50%)]\tLoss: 8651.646484\n",
      "Train Epoch: 930 [640/994 (62%)]\tLoss: 8670.456055\n",
      "Train Epoch: 930 [768/994 (75%)]\tLoss: 8647.454102\n",
      "Train Epoch: 930 [686/994 (88%)]\tLoss: 8667.099490\n",
      "====> Epoch: 930 Average loss: 8651.0430\n",
      "====> Test set loss: 8649.1992\n",
      "Train Epoch: 940 [0/994 (0%)]\tLoss: 8640.270508\n",
      "Train Epoch: 940 [128/994 (12%)]\tLoss: 8634.690430\n",
      "Train Epoch: 940 [256/994 (25%)]\tLoss: 8658.195312\n",
      "Train Epoch: 940 [384/994 (38%)]\tLoss: 8648.925781\n",
      "Train Epoch: 940 [512/994 (50%)]\tLoss: 8661.916992\n",
      "Train Epoch: 940 [640/994 (62%)]\tLoss: 8642.626953\n",
      "Train Epoch: 940 [768/994 (75%)]\tLoss: 8651.377930\n",
      "Train Epoch: 940 [686/994 (88%)]\tLoss: 8660.997449\n",
      "====> Epoch: 940 Average loss: 8649.5395\n",
      "====> Test set loss: 8648.6948\n",
      "Train Epoch: 950 [0/994 (0%)]\tLoss: 8653.331055\n",
      "Train Epoch: 950 [128/994 (12%)]\tLoss: 8659.316406\n",
      "Train Epoch: 950 [256/994 (25%)]\tLoss: 8646.554688\n",
      "Train Epoch: 950 [384/994 (38%)]\tLoss: 8620.133789\n",
      "Train Epoch: 950 [512/994 (50%)]\tLoss: 8653.021484\n",
      "Train Epoch: 950 [640/994 (62%)]\tLoss: 8675.862305\n",
      "Train Epoch: 950 [768/994 (75%)]\tLoss: 8638.473633\n",
      "Train Epoch: 950 [686/994 (88%)]\tLoss: 8644.762117\n",
      "====> Epoch: 950 Average loss: 8649.0578\n",
      "====> Test set loss: 8648.3588\n",
      "Train Epoch: 960 [0/994 (0%)]\tLoss: 8656.400391\n",
      "Train Epoch: 960 [128/994 (12%)]\tLoss: 8631.550781\n",
      "Train Epoch: 960 [256/994 (25%)]\tLoss: 8646.699219\n",
      "Train Epoch: 960 [384/994 (38%)]\tLoss: 8657.984375\n",
      "Train Epoch: 960 [512/994 (50%)]\tLoss: 8656.446289\n",
      "Train Epoch: 960 [640/994 (62%)]\tLoss: 8634.713867\n",
      "Train Epoch: 960 [768/994 (75%)]\tLoss: 8658.990234\n",
      "Train Epoch: 960 [686/994 (88%)]\tLoss: 8661.152423\n",
      "====> Epoch: 960 Average loss: 8650.1705\n",
      "====> Test set loss: 8651.6987\n",
      "Train Epoch: 970 [0/994 (0%)]\tLoss: 8661.141602\n",
      "Train Epoch: 970 [128/994 (12%)]\tLoss: 8670.594727\n",
      "Train Epoch: 970 [256/994 (25%)]\tLoss: 8645.958008\n",
      "Train Epoch: 970 [384/994 (38%)]\tLoss: 8647.172852\n",
      "Train Epoch: 970 [512/994 (50%)]\tLoss: 8642.901367\n",
      "Train Epoch: 970 [640/994 (62%)]\tLoss: 8640.130859\n",
      "Train Epoch: 970 [768/994 (75%)]\tLoss: 8643.141602\n",
      "Train Epoch: 970 [686/994 (88%)]\tLoss: 8639.301658\n",
      "====> Epoch: 970 Average loss: 8649.0793\n",
      "====> Test set loss: 8648.4158\n",
      "Train Epoch: 980 [0/994 (0%)]\tLoss: 8641.646484\n",
      "Train Epoch: 980 [128/994 (12%)]\tLoss: 8642.841797\n",
      "Train Epoch: 980 [256/994 (25%)]\tLoss: 8655.659180\n",
      "Train Epoch: 980 [384/994 (38%)]\tLoss: 8649.696289\n",
      "Train Epoch: 980 [512/994 (50%)]\tLoss: 8640.381836\n",
      "Train Epoch: 980 [640/994 (62%)]\tLoss: 8641.905273\n",
      "Train Epoch: 980 [768/994 (75%)]\tLoss: 8655.316406\n",
      "Train Epoch: 980 [686/994 (88%)]\tLoss: 8664.963010\n",
      "====> Epoch: 980 Average loss: 8648.5711\n",
      "====> Test set loss: 8648.2999\n",
      "Train Epoch: 990 [0/994 (0%)]\tLoss: 8646.432617\n",
      "Train Epoch: 990 [128/994 (12%)]\tLoss: 8670.570312\n",
      "Train Epoch: 990 [256/994 (25%)]\tLoss: 8653.010742\n",
      "Train Epoch: 990 [384/994 (38%)]\tLoss: 8652.725586\n",
      "Train Epoch: 990 [512/994 (50%)]\tLoss: 8632.278320\n",
      "Train Epoch: 990 [640/994 (62%)]\tLoss: 8634.266602\n",
      "Train Epoch: 990 [768/994 (75%)]\tLoss: 8665.906250\n",
      "Train Epoch: 990 [686/994 (88%)]\tLoss: 8642.649872\n",
      "====> Epoch: 990 Average loss: 8649.9437\n",
      "====> Test set loss: 8651.3608\n",
      "Train Epoch: 1000 [0/994 (0%)]\tLoss: 8660.524414\n",
      "Train Epoch: 1000 [128/994 (12%)]\tLoss: 8663.536133\n",
      "Train Epoch: 1000 [256/994 (25%)]\tLoss: 8638.280273\n",
      "Train Epoch: 1000 [384/994 (38%)]\tLoss: 8647.668945\n",
      "Train Epoch: 1000 [512/994 (50%)]\tLoss: 8659.133789\n",
      "Train Epoch: 1000 [640/994 (62%)]\tLoss: 8650.301758\n",
      "Train Epoch: 1000 [768/994 (75%)]\tLoss: 8644.217773\n",
      "Train Epoch: 1000 [686/994 (88%)]\tLoss: 8646.698342\n",
      "====> Epoch: 1000 Average loss: 8651.4339\n",
      "====> Test set loss: 8650.5589\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained our VAE. We can first evaluate it for the datapoints we trained it on, and get their embeddings in a vector, $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 100.20it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x_batch, z_batch = [], []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, _) in enumerate(tqdm(test_loader)):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        x_hat_, mean_, log_var = model(x)\n",
    "        x_batch.append(x_hat_.cpu().detach().numpy())\n",
    "        z_batch.append(mean_.cpu().detach().numpy())\n",
    "\n",
    "x_hat = np.concatenate(x_batch, axis=0)\n",
    "z = np.concatenate(z_batch, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeKF0wIYdZIx"
   },
   "source": [
    "We can now use the embeddings to describe our data. Much like for the PCA we can use the embeddings to give a dimentionallity reduced description of each cancer's expression profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rvnYbO2ZdZIy",
    "outputId": "fe7bfe90-fc1c-4b22-ce28-82887e6d1673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fee20426668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 429.35x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformed_patients = pd.DataFrame(data=z,columns=[\"Latent Variable 1\",\"Latent Variable 2\"],index=list(lusc.columns) + list(luad.columns))\n",
    "transformed_patients[\"Set\"]= ([\"LUSC\" for _ in lusc.columns]+[\"LUAD\" for _ in luad.columns])\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.set_style(\"white\")\n",
    "#sns.set_context(\"talk\")\n",
    "\n",
    "sns.lmplot(x=\"Latent Variable 1\",y=\"Latent Variable 2\", hue='Set', data=transformed_patients, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6WhJwTDdZIz"
   },
   "source": [
    "Here we see a non-complet separation of the patients based on two latent variables.\n",
    "\n",
    "Furter, we can use the network to generate \"typical\" expression profiles. The LUSC samples had embedings centering around [-2,0] and LUAD around [1,2]. We can generate two such profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zVFzjS1bdZI0",
    "outputId": "931c26d8-c578-4a9c-c5de-2c139cdf10d1"
   },
   "outputs": [],
   "source": [
    "z_fix = torch.tensor([[-2.,0.],[1.,2.]])\n",
    "\n",
    "z_fix = z_fix.to(device)\n",
    "x_fix = model.decode(z_fix).cpu().detach().numpy()\n",
    "predicted = pd.DataFrame(data=x_fix.T, index=combined.index, columns=[\"LUSC\", \"LUAD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JxtZLn6dZI1"
   },
   "source": [
    "We can now identify the genes most differential between the typical LUSC and LUAD sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rdGnIpvgdZI1",
    "outputId": "3fcf9449-bfea-443c-d2fc-179054e1c906"
   },
   "outputs": [],
   "source": [
    "predicted[\"diff\"] = predicted[\"LUSC\"] - predicted[\"LUAD\"]\n",
    "# predicted.sort_values(by='diff', ascending=False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKnwZ3DUdZI1"
   },
   "source": [
    "The genes pointing in a negative direction for the two components are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ORn2eerZdZI2",
    "outputId": "34a12ca0-4017-4d0f-afde-b5bca0b22e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACSL5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[\"diff\"].idxmin(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1PR5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[\"diff\"].idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-OJDYaFdZI2"
   },
   "source": [
    "Here the genes ACSL5 and S1PR5 seems to be the largest differentiators beteen th egenes in LUSC and LUAD. We can also note that as before, the Gene KRT17 seems quite different between the cancer types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SZ4Mo7rVdZI2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LUSC    0.765213\n",
       "LUAD    0.442689\n",
       "diff    0.322525\n",
       "Name: KRT17, dtype: float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.loc[\"KRT17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "https://github.com/statisticalbiotechnology/cb2030/blob/master/nb/pca/PCAofCarcinomas.ipynb",
     "timestamp": 1666187194313
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
